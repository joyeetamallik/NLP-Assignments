{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2\n",
    "\n",
    "## Question 1.** Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
    "\n",
    "\"xyz@gmail.com\",\n",
    "\"abc@yahoo.com\",\n",
    "\"xyz@hotmail.com\",\n",
    "\"abc@ineuron.ai\",\n",
    "\"xyz@outlook.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xyz@gmail.com',\n",
       " 'abc@yahoo.com',\n",
       " 'xyz@hotmail.com',\n",
       " 'abc@ineuron.ai',\n",
       " 'xyz@outlook.com']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=[\"xyz@gmail.com\", \"abc@yahoo.com\", \"xyz@hotmail.com\", \"abc@ineuron.ai\", \"xyz@outlook.com\"]\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@gmail.com', '@yahoo.com', '@hotmail.com', '@ineuron.ai', '@outlook.com']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Domain name from list of email addresses\n",
    "domain=[]\n",
    "j=0\n",
    "for i in li:\n",
    "    \n",
    "    all_data=(re.search(\"@[\\w.]+\", li[j]).group())\n",
    "    j=j+1\n",
    "    domain.append(all_data)\n",
    "    \n",
    "\n",
    "domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.** Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
    "\n",
    "[\"New Delhi is the capital of India\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Delhi is the capital of India\n",
      "The required word is :  ['New']\n"
     ]
    }
   ],
   "source": [
    "#Given sentence\n",
    "sent2=\"New Delhi is the capital of India\"\n",
    "print(sent2)\n",
    "print(\"The required word is : \",extract(sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    \n",
    "    a= re.findall(r\"^\\w+\",sent2)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 3.** Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
    "\n",
    "\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original sentence is :  In India, 184 people got affected with Corona virus and 4 are died.\n",
      "Sentence in lowercase:  in india, 184 people got affected with corona virus and 4 are died.\n",
      "Sentence without numbers :  In India,  people got affected with Corona virus and  are died.\n"
     ]
    }
   ],
   "source": [
    "sent3=\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "print(\" Original sentence is : \",sent3)\n",
    "print(\"Sentence in lowercase: \",lower(sent3))\n",
    "print(\"Sentence without numbers : \", rem_num(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case function\n",
    "def lower(text):\n",
    "    sent3_lower=sent3.lower()\n",
    "    return sent3_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing number\n",
    "def rem_num(text):\n",
    "    num=re.sub(r'\\d+', '',text)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.** Do stemming, lemmatization and tokenization from the following sentence.\n",
    "\n",
    "\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import wordnet \n",
    "lemma = wordnet.WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Original sentence is :  I hope that, when I have built up my savings, I will be able to travel to Hawai.\n",
      "\n",
      " Tokenized list is:  ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'savings', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.']\n",
      "\n",
      " List after applying Lemmatization :  ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'build', 'up', 'my', 'save', ',', 'I', 'will', 'be', 'able', 'to', 'travel', 'to', 'Hawai', '.']\n",
      "\n",
      " List after applying Stemming :  ['I', 'hope', 'that', ',', 'when', 'I', 'have', 'built', 'up', 'my', 'save', ',', 'I', 'will', 'be', 'abl', 'to', 'travel', 'to', 'hawai', '.']\n"
     ]
    }
   ],
   "source": [
    "sent4=\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n",
    "print(\" \\n Original sentence is : \",sent4)\n",
    "print(\"\\n Tokenized list is: \",tokenize(sent4))\n",
    "print(\"\\n List after applying Lemmatization : \", lemmatize_word(sent4))\n",
    "print(\"\\n List after applying Stemming : \", s_words(sent4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentence\n",
    "\n",
    "def tokenize(text):\n",
    "    tok=word_tokenize(text)\n",
    "    return tok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lemmatize string \n",
    "def lemmatize_word(text): \n",
    "    lemmas = [lemma.lemmatize(word, pos ='v') for word in tokenize(text)] \n",
    "    return lemmas \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "stem1 = PorterStemmer() \n",
    "\n",
    "def s_words(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stem1.stem(word) for word in tokenize(text)] \n",
    "    return stems \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.** Create one python program from the following sentence.\n",
    "\n",
    "\"I love NLP, not you\"\n",
    "\n",
    "output : ['I', 'l', 'N', 'n', 'y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Original sentence is :  I love NLP, not you\n",
      " \n",
      " First Letter of sentence is :  ['I', 'l', 'N', ',', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "sent5= \"I love NLP, not you\"\n",
    "print(\" \\n Original sentence is : \",sent5)\n",
    "print(\" \\n First Letter of sentence is : \",firstletter(sent5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstletter(text):\n",
    "    li=[i[0] for i in word_tokenize(text)]\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
